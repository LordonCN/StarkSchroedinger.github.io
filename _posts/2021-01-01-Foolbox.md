---
layout:     post
title:      "Foolbox: A Python toolbox to benchmark the robustness of machine learning models"
subtitle:   "论文精度笔记"
date:       2021-01-01
author:     "Felix Zhang"
header-img: "img/in-post/2021-01-01-Foolbox/bg.JPG"
catalog: true
tags:
   - Deep Learning
   - Adversarial Machine Learning
   - Paper Notes
---

Foolbox给我们提供了一个专门用来产生攻击并评价不同ML模型对攻击鲁棒性的工具箱。这个工具箱

机器的预测可能会因为某些细小的改动而产生极大的差异，这事和人脑不同的地方，这就是所谓的Adversarial Attack。为了量化系统对这种攻击的鲁棒性，Szegedy在提出了基于average size of the minimum adversarial perturbation across many examples的评价标准后，焦点落在了如何寻找global minimum adversarial purturbation上。现有的办法基本上都是对样本实施尽可能多的攻击，并且在所有有效攻击中取平均，但是现在大部分实施攻击的方法都受限于——不同平台、框架下的可实施性和可比性。

